{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost Analysis with Feather File\n",
    "\n",
    "This notebook demonstrates how to read a feather file and fit an XGBoost model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Feather File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'your_file.feather' with the actual path to your feather file\n",
    "file_path = 'your_file.feather'\n",
    "\n",
    "try:\n",
    "    # Read the feather file\n",
    "    df = pd.read_feather(file_path)\n",
    "    print(f\"Data loaded successfully!\")\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(f\"\\nColumns: {list(df.columns)}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"File '{file_path}' not found. Please check the file path.\")\n",
    "    # Create sample data for demonstration\n",
    "    print(\"Creating sample data for demonstration...\")\n",
    "    np.random.seed(42)\n",
    "    n_samples = 1000\n",
    "    df = pd.DataFrame({\n",
    "        'feature1': np.random.normal(0, 1, n_samples),\n",
    "        'feature2': np.random.normal(2, 0.5, n_samples),\n",
    "        'feature3': np.random.randint(0, 5, n_samples),\n",
    "        'feature4': np.random.exponential(1, n_samples),\n",
    "        'target': np.random.randint(0, 3, n_samples)  # Multi-class target\n",
    "    })\n",
    "    print(f\"Sample data created with shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic information about the dataset\n",
    "print(\"Dataset Info:\")\n",
    "print(df.info())\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df.head())\n",
    "print(\"\\nBasic statistics:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Check data types\n",
    "print(\"\\nData types:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data for XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You'll need to specify which column is your target variable\n",
    "# For this example, we'll assume the last column is the target\n",
    "# Adjust this based on your actual data\n",
    "\n",
    "# Identify target column (modify as needed)\n",
    "target_column = df.columns[-1]  # Assuming last column is target\n",
    "print(f\"Using '{target_column}' as target variable\")\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop(columns=[target_column])\n",
    "y = df[target_column]\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"Target distribution:\")\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle categorical variables if any\n",
    "categorical_columns = X.select_dtypes(include=['object', 'category']).columns\n",
    "if len(categorical_columns) > 0:\n",
    "    print(f\"Categorical columns found: {list(categorical_columns)}\")\n",
    "    # Apply label encoding to categorical variables\n",
    "    le = LabelEncoder()\n",
    "    for col in categorical_columns:\n",
    "        X[col] = le.fit_transform(X[col])\n",
    "    print(\"Categorical variables encoded\")\n",
    "else:\n",
    "    print(\"No categorical variables found\")\n",
    "\n",
    "# Handle missing values if any\n",
    "if X.isnull().sum().sum() > 0:\n",
    "    print(\"Filling missing values with median...\")\n",
    "    X = X.fillna(X.median())\n",
    "    print(\"Missing values handled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Test set shape: {X_test.shape}\")\n",
    "print(f\"Training target distribution:\")\n",
    "print(y_train.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine if this is a classification or regression problem\n",
    "is_classification = len(y.unique()) < 20 and y.dtype in ['int64', 'object', 'category']\n",
    "\n",
    "if is_classification:\n",
    "    print(\"Detected classification problem\")\n",
    "    # XGBoost Classifier\n",
    "    model = xgb.XGBClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        eval_metric='mlogloss' if len(y.unique()) > 2 else 'logloss'\n",
    "    )\n",
    "else:\n",
    "    print(\"Detected regression problem\")\n",
    "    # XGBoost Regressor\n",
    "    model = xgb.XGBRegressor(\n",
    "        n_estimators=100,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "# Fit the model\n",
    "print(\"Training XGBoost model...\")\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Model training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Predictions and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "if is_classification:\n",
    "    # Classification metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "else:\n",
    "    # Regression metrics\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "    print(f\"Root Mean Squared Error: {rmse:.4f}\")\n",
    "    print(f\"R² Score: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Feature Importance:\")\n",
    "print(feature_importance)\n",
    "\n",
    "# Plot feature importance (optional - requires matplotlib)\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(feature_importance['feature'], feature_importance['importance'])\n",
    "    plt.xlabel('Feature Importance')\n",
    "    plt.title('XGBoost Feature Importance')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "except ImportError:\n",
    "    print(\"Matplotlib not available for plotting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Model Summary ===\")\n",
    "print(f\"Model type: {type(model).__name__}\")\n",
    "print(f\"Number of features: {X.shape[1]}\")\n",
    "print(f\"Training samples: {X_train.shape[0]}\")\n",
    "print(f\"Test samples: {X_test.shape[0]}\")\n",
    "print(f\"Problem type: {'Classification' if is_classification else 'Regression'}\")\n",
    "\n",
    "if is_classification:\n",
    "    print(f\"Number of classes: {len(y.unique())}\")\n",
    "    print(f\"Test accuracy: {accuracy:.4f}\")\n",
    "else:\n",
    "    print(f\"Test R² score: {r2:.4f}\")\n",
    "    print(f\"Test RMSE: {rmse:.4f}\")\n",
    "\n",
    "print(\"\\nTop 3 most important features:\")\n",
    "for i, (idx, row) in enumerate(feature_importance.head(3).iterrows()):\n",
    "    print(f\"{i+1}. {row['feature']}: {row['importance']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
